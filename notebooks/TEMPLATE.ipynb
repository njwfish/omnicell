{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 10:30:10,248 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/repogle_k562_essential_raw.yaml\n",
      "2025-01-31 10:30:10,250 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNB_raw.yaml\n",
      "2025-01-31 10:30:10,252 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/adamson_INCOMPLETE.yaml\n",
      "2025-01-31 10:30:10,253 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNB_HVG.yaml\n",
      "2025-01-31 10:30:10,255 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/kang.yaml\n",
      "2025-01-31 10:30:10,257 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/essential_gene_knockouts_raw.yaml\n",
      "2025-01-31 10:30:10,258 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNG_raw_INCOMPLETE.yaml\n",
      "2025-01-31 10:30:10,260 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNG_raw.yaml\n",
      "2025-01-31 10:30:10,262 - INFO - Loading training data at path: /orcd/data/omarabu/001/Omnicell_datasets/repogle_k562_essential_raw/K562_essential_raw_singlecell_01.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 10:30:14,807 - INFO - Loaded unpreprocessed data, # of data points: 310385, # of genes: 8563.\n",
      "2025-01-31 10:30:14,808 - INFO - Preprocessing training data\n",
      "2025-01-31 10:30:14,810 - INFO - Using identity features for perturbations\n",
      "2025-01-31 10:30:14,933 - INFO - Removing observations with perturbations not in the dataset as a column\n",
      "2025-01-31 10:30:15,119 - INFO - Removed 189 perturbations that were not in the dataset columns and 0 perturbations that did not have an embedding for a total of 189 perturbations removed out of an initial 2058 perturbations\n",
      "/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/data/loader.py:178: ImplicitModificationWarning: Setting element `.obsm['embedding']` of view, initializing view as actual.\n",
      "  adata.obsm[\"embedding\"] = adata.X.toarray().astype('float32')\n",
      "2025-01-31 10:30:52,099 - INFO - Doing OOD split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded:\n",
      "- Number of cells: 279630\n",
      "- Input dimension: 8563\n",
      "- Number of perturbations: 1850\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the path to the directory containing the omnicell package\n",
    "# Assuming the omnicell package is in the parent directory of your notebook\n",
    "sys.path.append('..')  # Adjust this path as needed\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from omnicell.config.config import Config, ETLConfig, ModelConfig, DatasplitConfig, EvalConfig, EmbeddingConfig\n",
    "from omnicell.data.loader import DataLoader\n",
    "from omnicell.constants import PERT_KEY, GENE_EMBEDDING_KEY, CONTROL_PERT\n",
    "from train import get_model\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure paths\n",
    "MODEL_CONFIG = ModelConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/models/linear_mean_model.yaml\")\n",
    "ETL_CONFIG = ETLConfig(name = \"no_preprocessing\", log1p = False, drop_unmatched_perts = True)\n",
    "EMBEDDING_CONFIG = EmbeddingConfig(pert_embedding='GenePT')\n",
    "\n",
    "SPLIT_CONFIG = DatasplitConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/splits/repogle_k562_essential_raw/random_splits/rs_accP_k562_ood_ss:ns_20_2_most_pert_0.1/split_0/split_config.yaml\")\n",
    "EVAL_CONFIG = EvalConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/splits/repogle_k562_essential_raw/random_splits/rs_accP_k562_ood_ss:ns_20_2_most_pert_0.1/split_0/eval_config.yaml\")  # Set this if you want to run evaluations\n",
    "\n",
    "# Load configurations\n",
    "config = Config(model_config=MODEL_CONFIG,\n",
    "                 etl_config=ETL_CONFIG, \n",
    "                 datasplit_config=SPLIT_CONFIG, \n",
    "                 eval_config=EVAL_CONFIG)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Alternatively you can initialize the config objects manually as follows:\n",
    "# etl_config = ETLConfig(name = XXX, log1p = False, drop_unmatched_perts = False, ...)\n",
    "# model_config = ...\n",
    "# embedding_config = ...\n",
    "# datasplit_config = ...\n",
    "# eval_config = ...\n",
    "# config = Config(etl_config, model_config, datasplit_config, eval_config)\n",
    "\n",
    "\n",
    "config.etl_config.pert_embedding = 'bioBERT'\n",
    "config.etl_config.drop_unmatched_perts = True\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize data loader and load training data\n",
    "loader = DataLoader(config)\n",
    "adata, pert_rep_map = loader.get_training_data()\n",
    "\n",
    "# Get dimensions and perturbation IDs\n",
    "input_dim = adata.obsm['embedding'].shape[1]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pert_ids = adata.obs[PERT_KEY].unique()\n",
    "gene_emb_dim = adata.varm[GENE_EMBEDDING_KEY].shape[1] if GENE_EMBEDDING_KEY in adata.varm else None\n",
    "\n",
    "print(f\"Data loaded:\")\n",
    "print(f\"- Number of cells: {adata.shape[0]}\")\n",
    "print(f\"- Input dimension: {input_dim}\")\n",
    "print(f\"- Number of perturbations: {len(pert_ids)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 10:30:59,352 - INFO - Mean model selected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = get_model(config.model_config.name, config.model_config.parameters, loader, pert_rep_map, input_dim, device, pert_ids, gene_emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/models/mean_models/model.py:72: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  pert_means = df.groupby('perturbation').mean()\n"
     ]
    }
   ],
   "source": [
    "model.train(adata, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from scipy.sparse import issparse\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def r2_mse_filename(pert, cell):\n",
    "    return f'r2_and_mse_{pert}_{cell}.json'\n",
    "\n",
    "def c_r_filename(pert, cell):\n",
    "    return f'c_r_results_{pert}_{cell}.json'\n",
    "\n",
    "def DEGs_overlap_filename(pert, cell):   \n",
    "    return f'DEGs_overlaps_{pert}_{cell}.json'\n",
    "\n",
    "\n",
    "def get_DEG_with_direction(gene, score):\n",
    "    if score > 0:\n",
    "        return(f'{gene}+')\n",
    "    else:\n",
    "        return(f'{gene}-')\n",
    "        \n",
    "def to_dense(X):\n",
    "    if issparse(X):\n",
    "        return X.toarray()\n",
    "    else:\n",
    "        return np.asarray(X)\n",
    "\n",
    "def efficient_correlation_pearsonr(U, V):\n",
    "    \"\"\"\n",
    "    Compute squared Pearson correlation between correlation matrices \n",
    "    for matrices of different ranks\n",
    "    U: (n_samples x k1) matrix\n",
    "    V: (n_samples x k2) matrix\n",
    "    \"\"\"\n",
    "    # Center the data\n",
    "    U_centered = U - U.mean(axis=1, keepdims=True)\n",
    "    V_centered = V - V.mean(axis=1, keepdims=True)\n",
    "    \n",
    "    # Normalize rows\n",
    "    U_norms = np.sqrt(np.sum(U_centered * U_centered, axis=1, keepdims=True))\n",
    "    V_norms = np.sqrt(np.sum(V_centered * V_centered, axis=1, keepdims=True))\n",
    "    \n",
    "    U_normalized = U_centered / U_norms\n",
    "    V_normalized = V_centered / V_norms\n",
    "    \n",
    "    # Work with smaller matrices\n",
    "    UTU = U_normalized.T @ U_normalized  # k1×k1 matrix\n",
    "    VTV = V_normalized.T @ V_normalized  # k2×k2 matrix\n",
    "    UV = U_normalized.T @ V_normalized   # k1×k2 matrix\n",
    "    \n",
    "    # Compute means efficiently\n",
    "    mean_UTU = np.sum(UTU) / (U.shape[0] ** 2)\n",
    "    mean_VTV = np.sum(VTV) / (V.shape[0] ** 2)\n",
    "    \n",
    "    # Use trace tricks with different sized matrices\n",
    "    # For matrices of different sizes, tr(UU^T VV^T) = tr((U^TV)(V^TU)) = sum(UV * VU)\n",
    "    # print(UV.shape, V_normalized.T.shape, U_normalized.shape)\n",
    "    trace_UUTVVT = np.sum(UV.T * (V_normalized.T @ U_normalized))\n",
    "    trace_UUTUUT = np.sum(UTU * UTU)\n",
    "    trace_VVTVVT = np.sum(VTV * VTV)\n",
    "    \n",
    "    n_squared = U.shape[0] ** 2\n",
    "    \n",
    "    # Compute correlation\n",
    "    numerator = trace_UUTVVT - n_squared * mean_UTU * mean_VTV\n",
    "    denominator = np.sqrt((trace_UUTUUT - n_squared * mean_UTU ** 2) * \n",
    "                         (trace_VVTVVT - n_squared * mean_VTV ** 2))\n",
    "    \n",
    "    r = numerator / denominator\n",
    "    return r\n",
    "\n",
    "def efficient_covariance_pearsonr(U, V):\n",
    "    \"\"\"\n",
    "    Compute squared Pearson correlation between covariance matrices \n",
    "    for matrices of different ranks\n",
    "    U: (n_samples x k1) matrix\n",
    "    V: (n_samples x k2) matrix\n",
    "    \"\"\"\n",
    "    # Center the data\n",
    "    U_centered = U - U.mean(axis=1, keepdims=True)\n",
    "    V_centered = V - V.mean(axis=1, keepdims=True)\n",
    "    \n",
    "    # For covariance, we don't normalize by row norms\n",
    "    # Compute smaller matrices directly\n",
    "    UTU = U_centered.T @ U_centered  # k1×k1 matrix\n",
    "    VTV = V_centered.T @ V_centered  # k2×k2 matrix\n",
    "    UV = U_centered.T @ V_centered   # k1×k2 matrix\n",
    "    \n",
    "    # Compute means efficiently\n",
    "    mean_UTU = np.sum(UTU) / (U.shape[0] ** 2)\n",
    "    mean_VTV = np.sum(VTV) / (V.shape[0] ** 2)\n",
    "    \n",
    "    # Use trace tricks with different sized matrices\n",
    "    trace_UUTVVT = np.sum(UV.T * (V_centered.T @ U_centered))\n",
    "    trace_UUTUUT = np.sum(UTU * UTU)\n",
    "    trace_VVTVVT = np.sum(VTV * VTV)\n",
    "    \n",
    "    n_squared = U.shape[0] ** 2\n",
    "    \n",
    "    # Compute correlation\n",
    "    numerator = trace_UUTVVT - n_squared * mean_UTU * mean_VTV\n",
    "    denominator = np.sqrt((trace_UUTUUT - n_squared * mean_UTU ** 2) * \n",
    "                         (trace_VVTVVT - n_squared * mean_VTV ** 2))\n",
    "    \n",
    "    r = numerator / denominator\n",
    "    return r\n",
    "\n",
    "def get_eval(ctrl_adata, true_adata, pred_adata, DEGs, DEG_vals, pval_threshold, lfc_threshold):\n",
    "        \n",
    "    results_dict =  {}\n",
    "    \n",
    "    logger.debug(f\"Computing R, R2, and MSE metrics\")\n",
    "    ctrl_X = to_dense(ctrl_adata.X)\n",
    "    true_X = to_dense(true_adata.X)\n",
    "    pred_X = to_dense(pred_adata.X)\n",
    "\n",
    "    ctrl_mean = ctrl_X.mean(axis = 0)\n",
    "\n",
    "    true_mean = true_X.mean(axis = 0)\n",
    "    true_var = true_X.var(axis = 0)\n",
    "    \n",
    "    pred_mean = pred_X.mean(axis = 0)\n",
    "    pred_var = pred_X.var(axis = 0)\n",
    "    print(\"mean and var\")\n",
    "    \n",
    "    # true_corr_mtx = np.corrcoef(true_X, rowvar=False).flatten()\n",
    "    # true_cov_mtx = np.cov(true_X, rowvar=False).flatten()\n",
    "        \n",
    "    # pred_corr_mtx = np.corrcoef(pred_X, rowvar=False).flatten()\n",
    "    # pred_cov_mtx = np.cov(pred_X, rowvar=False).flatten()\n",
    "\n",
    "    true_sub_diff = true_mean - ctrl_mean\n",
    "    pred_sub_diff = pred_mean - ctrl_mean\n",
    "\n",
    "    true_diff = np.expm1(true_mean) - np.expm1(ctrl_mean)\n",
    "    pred_diff = np.expm1(pred_mean) - np.expm1(ctrl_mean)\n",
    "\n",
    "    results_dict['all_genes_mean_sub_diff_R'] = pearsonr(true_sub_diff, pred_sub_diff)[0]\n",
    "    results_dict['all_genes_mean_sub_diff_R2'] = pearsonr(true_sub_diff, pred_sub_diff)[0]**2\n",
    "    results_dict['all_genes_mean_sub_diff_MSE'] = (np.square(true_sub_diff - pred_sub_diff)).mean(axis=0)\n",
    "    print(\"mean sub diff\")\n",
    "\n",
    "    results_dict['all_genes_mean_fold_diff_R'] = pearsonr(true_diff, pred_diff)[0]\n",
    "    results_dict['all_genes_mean_fold_diff_R2'] = pearsonr(true_diff, pred_diff)[0]**2\n",
    "    results_dict['all_genes_mean_fold_diff_MSE'] = (np.square(true_diff - pred_diff)).mean(axis=0)\n",
    "\n",
    "    results_dict['all_genes_mean_R'] = pearsonr(true_mean, pred_mean)[0]\n",
    "    results_dict['all_genes_mean_R2'] = pearsonr(true_mean, pred_mean)[0]**2\n",
    "    results_dict['all_genes_mean_MSE'] = (np.square(true_mean - pred_mean)).mean(axis=0)\n",
    "\n",
    "    results_dict['all_genes_var_R'] = pearsonr(true_var, pred_var)[0]\n",
    "    results_dict['all_genes_var_R2'] = pearsonr(true_var, pred_var)[0]**2\n",
    "    results_dict['all_genes_var_MSE'] = (np.square(true_var - pred_var)).mean(axis=0)\n",
    "\n",
    "    corr_r = efficient_correlation_pearsonr(true_X.T, pred_X.T)\n",
    "    cov_r = efficient_covariance_pearsonr(true_X.T, pred_X.T)\n",
    "\n",
    "    results_dict['all_genes_corr_mtx_R'] = corr_r # pearsonr(true_corr_mtx.flatten(), pred_corr_mtx.flatten())[0]\n",
    "    results_dict['all_genes_corr_mtx_R2'] = corr_r**2 # pearsonr(true_corr_mtx.flatten(), pred_corr_mtx.flatten())[0]**2\n",
    "    # results_dict['all_genes_corr_mtx_MSE'] = (np.square(true_corr_mtx.flatten() - pred_corr_mtx.flatten())).mean(axis=0)\n",
    "\n",
    "    results_dict['all_genes_cov_mtx_R'] = cov_r\n",
    "    results_dict['all_genes_cov_mtx_R2'] = cov_r**2\n",
    "    # results_dict['all_genes_cov_mtx_MSE'] = (np.square(true_cov_mtx.flatten() - pred_cov_mtx.flatten())).mean(axis=0)\n",
    "\n",
    "    if lfc_threshold:   \n",
    "        significant_DEGs = DEGs[(DEGs['pvals_adj'] < pval_threshold) & (abs(DEGs) > lfc_threshold)]\n",
    "    else:\n",
    "        significant_DEGs = DEGs[DEGs['pvals_adj'] < pval_threshold]\n",
    "    num_DEGs = len(significant_DEGs)\n",
    "    DEG_vals.insert(0, num_DEGs)\n",
    "\n",
    "\n",
    "    logger.debug(f\"Significant DEGs {significant_DEGs}\")\n",
    "    \n",
    "    for val in DEG_vals:\n",
    "\n",
    "        logger.debug(f\"Computing R, R2, and MSE metrics for top {val} DEGs\")\n",
    "\n",
    "        #If val == 1 we can't\n",
    "        if ((val > num_DEGs) or (val == 0) or (val == 1)):\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_mean_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_mean_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_mean_MSE'] = None\n",
    "            \n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_mean_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_mean_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_mean_MSE'] = None\n",
    "            \n",
    "            results_dict[f'Top_{val}_DEGs_mean_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_mean_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_mean_MSE'] = None\n",
    "\n",
    "            results_dict[f'Top_{val}_DEGs_var_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_var_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_var_MSE'] = None\n",
    "            \n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_MSE'] = None\n",
    "            \n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_MSE'] = None\n",
    "        \n",
    "        else:\n",
    "            top_DEGs = significant_DEGs[0:val].index.map(int)\n",
    "\n",
    "            logger.debug(f\"Top DEGs: {top_DEGs}\")\n",
    "\n",
    "\n",
    "            #Reshape --> If there is a single gene, the shape is (1,) and we need to reshape it to (1,1)\n",
    "\n",
    "            ctrl_mean = to_dense(ctrl_X[:,top_DEGs]).mean(axis = 0)\n",
    "            true_mean = to_dense(true_X[:,top_DEGs]).mean(axis = 0)\n",
    "\n",
    "            logger.debug(f\"Shape ctrl_adata with top DEGs: {ctrl_adata[:,top_DEGs].X.shape}, shape true_adata with top DEGs: {true_adata[:,top_DEGs].X.shape}\")\n",
    "\n",
    "\n",
    "            true_var = to_dense(true_X[:,top_DEGs]).var(axis = 0)\n",
    "            true_corr_mtx = np.corrcoef(to_dense(true_X[:,top_DEGs]), rowvar=False).flatten()\n",
    "            true_cov_mtx = np.cov(to_dense(true_X[:,top_DEGs]), rowvar=False).flatten()\n",
    "\n",
    "            pred_mean = to_dense(pred_X[:,top_DEGs]).mean(axis = 0)\n",
    "            logger.debug(f\"Shape of true_mean shape: {true_mean.shape}, ctrl_mean shape: {ctrl_mean.shape}, pred_mean shape: {pred_mean.shape}\")\n",
    "\n",
    "            pred_var = to_dense(pred_X[:,top_DEGs]).var(axis = 0)\n",
    "            pred_corr_mtx = np.corrcoef(to_dense(pred_X[:,top_DEGs]), rowvar=False).flatten()\n",
    "            pred_cov_mtx = np.cov(to_dense(pred_X[:,top_DEGs]), rowvar=False).flatten()\n",
    "\n",
    "            logger.debug(f\"Shape of true_var shape: {true_var.shape}, pred_var shape: {pred_var.shape}\")\n",
    "\n",
    "            true_sub_diff = true_mean - ctrl_mean\n",
    "            pred_sub_diff = pred_mean - ctrl_mean\n",
    "        \n",
    "            # inverse log1p to get sub change\n",
    "            true_diff = np.expm1(true_mean) - np.expm1(ctrl_mean)\n",
    "            pred_diff = np.expm1(pred_mean) - np.expm1(ctrl_mean)\n",
    "\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_R'] = pearsonr(true_sub_diff, pred_sub_diff)[0]\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_R2'] = pearsonr(true_sub_diff, pred_sub_diff)[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_MSE'] = (np.square(true_sub_diff - pred_sub_diff)).mean(axis=0)\n",
    "        \n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_R'] = pearsonr(true_diff, pred_diff)[0]\n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_R2'] = pearsonr(true_diff, pred_diff)[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_MSE'] = (np.square(true_diff - pred_diff)).mean(axis=0)\n",
    "    \n",
    "            results_dict[f'Top_{val}_DEGs_mean_R'] = pearsonr(true_mean, pred_mean)[0]\n",
    "            results_dict[f'Top_{val}_DEGs_mean_R2'] = pearsonr(true_mean, pred_mean)[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_mean_MSE'] = (np.square(true_mean - pred_mean)).mean(axis=0)\n",
    "\n",
    "            results_dict[f'Top_{val}_DEGs_var_R'] = pearsonr(true_var, pred_var)[0]\n",
    "            results_dict[f'Top_{val}_DEGs_var_R2'] = pearsonr(true_var, pred_var)[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_var_MSE'] = (np.square(true_var - pred_var)).mean(axis=0)\n",
    "\n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_R'] = pearsonr(true_corr_mtx.flatten(), pred_corr_mtx.flatten())[0]\n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_R2'] = pearsonr(true_corr_mtx.flatten(), pred_corr_mtx.flatten())[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_MSE'] = (np.square(true_corr_mtx.flatten() - pred_corr_mtx.flatten())).mean(axis=0)\n",
    "\n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_R'] = pearsonr(true_cov_mtx.flatten(), pred_cov_mtx.flatten())[0]\n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_R2'] = pearsonr(true_cov_mtx.flatten(), pred_cov_mtx.flatten())[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_MSE'] = (np.square(true_cov_mtx.flatten() - pred_cov_mtx.flatten())).mean(axis=0)\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and var\n",
      "mean sub diff\n"
     ]
    }
   ],
   "source": [
    "r2_and_mse = get_eval(control, true_pert, pred_pert, true_DEGs_df, [100,50,20], pval_threshold, log_fold_change_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from scipy.sparse import issparse\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def r2_mse_filename(pert, cell):\n",
    "    return f'r2_and_mse_{pert}_{cell}.json'\n",
    "\n",
    "def c_r_filename(pert, cell):\n",
    "    return f'c_r_results_{pert}_{cell}.json'\n",
    "\n",
    "def DEGs_overlap_filename(pert, cell):   \n",
    "    return f'DEGs_overlaps_{pert}_{cell}.json'\n",
    "\n",
    "\n",
    "def get_DEG_with_direction(gene, score):\n",
    "    if score > 0:\n",
    "        return(f'{gene}+')\n",
    "    else:\n",
    "        return(f'{gene}-')\n",
    "        \n",
    "def to_dense(X):\n",
    "    if issparse(X):\n",
    "        return X.toarray()\n",
    "    else:\n",
    "        return np.asarray(X)\n",
    "\n",
    "def get_DEGs(control_adata, target_adata):\n",
    "    temp_concat = anndata.concat([control_adata, target_adata], label = 'batch')\n",
    "    sc.tl.rank_genes_groups(\n",
    "        temp_concat, 'batch', method='wilcoxon', \n",
    "        groups = ['1'], ref = '0', rankby_abs = True, tie_correct=True\n",
    "    )\n",
    "\n",
    "    rankings = temp_concat.uns['rank_genes_groups']\n",
    "    result_df = pd.DataFrame({'scores': rankings['scores']['1'],\n",
    "                     'pvals_adj': rankings['pvals_adj']['1'],\n",
    "                     'lfc': rankings['logfoldchanges']['1']},\n",
    "                    index = rankings['names']['1'])\n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "def get_eval(ctrl_adata, true_adata, pred_adata, DEGs, DEG_vals, pval_threshold, lfc_threshold):\n",
    "        \n",
    "    results_dict =  {}\n",
    "    \n",
    "    logger.debug(f\"Computing R, R2, and MSE metrics\")\n",
    "    ctrl_X = to_dense(ctrl_adata.X)\n",
    "    true_X = to_dense(true_adata.X)\n",
    "    pred_X = to_dense(pred_adata.X)\n",
    "\n",
    "    ctrl_mean = ctrl_X.mean(axis = 0)\n",
    "\n",
    "    true_mean = true_X.mean(axis = 0)\n",
    "    true_var = true_X.var(axis = 0)\n",
    "    \n",
    "    pred_mean = pred_X.mean(axis = 0)\n",
    "    pred_var = pred_X.var(axis = 0)\n",
    "    \n",
    "    true_corr_mtx = np.corrcoef(true_X, rowvar=False).flatten()\n",
    "    true_cov_mtx = np.cov(true_X, rowvar=False).flatten()\n",
    "        \n",
    "    pred_corr_mtx = np.corrcoef(pred_X, rowvar=False).flatten()\n",
    "    pred_cov_mtx = np.cov(pred_X, rowvar=False).flatten()\n",
    "\n",
    "    true_sub_diff = true_mean - ctrl_mean\n",
    "    pred_sub_diff = pred_mean - ctrl_mean\n",
    "\n",
    "    true_diff = np.expm1(true_mean) - np.expm1(ctrl_mean)\n",
    "    pred_diff = np.expm1(pred_mean) - np.expm1(ctrl_mean)\n",
    "\n",
    "    results_dict['all_genes_mean_sub_diff_R'] = pearsonr(true_sub_diff, pred_sub_diff)[0]\n",
    "    results_dict['all_genes_mean_sub_diff_R2'] = pearsonr(true_sub_diff, pred_sub_diff)[0]**2\n",
    "    results_dict['all_genes_mean_sub_diff_MSE'] = (np.square(true_sub_diff - pred_sub_diff)).mean(axis=0)\n",
    "\n",
    "    results_dict['all_genes_mean_fold_diff_R'] = pearsonr(true_diff, pred_diff)[0]\n",
    "    results_dict['all_genes_mean_fold_diff_R2'] = pearsonr(true_diff, pred_diff)[0]**2\n",
    "    results_dict['all_genes_mean_fold_diff_MSE'] = (np.square(true_diff - pred_diff)).mean(axis=0)\n",
    "    \n",
    "    results_dict['all_genes_mean_R'] = pearsonr(true_mean, pred_mean)[0]\n",
    "    results_dict['all_genes_mean_R2'] = pearsonr(true_mean, pred_mean)[0]**2\n",
    "    results_dict['all_genes_mean_MSE'] = (np.square(true_mean - pred_mean)).mean(axis=0)\n",
    "\n",
    "    results_dict['all_genes_var_R'] = pearsonr(true_var, pred_var)[0]\n",
    "    results_dict['all_genes_var_R2'] = pearsonr(true_var, pred_var)[0]**2\n",
    "    results_dict['all_genes_var_MSE'] = (np.square(true_var - pred_var)).mean(axis=0)\n",
    "\n",
    "    results_dict['all_genes_corr_mtx_R'] = pearsonr(true_corr_mtx.flatten(), pred_corr_mtx.flatten())[0]\n",
    "    results_dict['all_genes_corr_mtx_R2'] = pearsonr(true_corr_mtx.flatten(), pred_corr_mtx.flatten())[0]**2\n",
    "    results_dict['all_genes_corr_mtx_MSE'] = (np.square(true_corr_mtx.flatten() - pred_corr_mtx.flatten())).mean(axis=0)\n",
    "\n",
    "    results_dict['all_genes_cov_mtx_R'] = pearsonr(true_cov_mtx.flatten(), pred_cov_mtx.flatten())[0]\n",
    "    results_dict['all_genes_cov_mtx_R2'] = pearsonr(true_cov_mtx.flatten(), pred_cov_mtx.flatten())[0]**2\n",
    "    results_dict['all_genes_cov_mtx_MSE'] = (np.square(true_cov_mtx.flatten() - pred_cov_mtx.flatten())).mean(axis=0)\n",
    "\n",
    "    if lfc_threshold:   \n",
    "        significant_DEGs = DEGs[(DEGs['pvals_adj'] < pval_threshold) & (abs(DEGs) > lfc_threshold)]\n",
    "    else:\n",
    "        significant_DEGs = DEGs[DEGs['pvals_adj'] < pval_threshold]\n",
    "    num_DEGs = len(significant_DEGs)\n",
    "    DEG_vals.insert(0, num_DEGs)\n",
    "\n",
    "\n",
    "    logger.debug(f\"Significant DEGs {significant_DEGs}\")\n",
    "    \n",
    "    for val in DEG_vals:\n",
    "\n",
    "        logger.debug(f\"Computing R, R2, and MSE metrics for top {val} DEGs\")\n",
    "\n",
    "        #If val == 1 we can't\n",
    "        if ((val > num_DEGs) or (val == 0) or (val == 1)):\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_mean_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_mean_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_mean_MSE'] = None\n",
    "            \n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_mean_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_mean_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_mean_MSE'] = None\n",
    "            \n",
    "            results_dict[f'Top_{val}_DEGs_mean_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_mean_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_mean_MSE'] = None\n",
    "\n",
    "            results_dict[f'Top_{val}_DEGs_var_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_var_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_var_MSE'] = None\n",
    "            \n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_MSE'] = None\n",
    "            \n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_R'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_R2'] = None\n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_MSE'] = None\n",
    "        \n",
    "        else:\n",
    "            top_DEGs = significant_DEGs[0:val].index.map(int)\n",
    "\n",
    "            logger.debug(f\"Top DEGs: {top_DEGs}\")\n",
    "\n",
    "\n",
    "            #Reshape --> If there is a single gene, the shape is (1,) and we need to reshape it to (1,1)\n",
    "\n",
    "            ctrl_mean = to_dense(ctrl_X[:,top_DEGs]).mean(axis = 0)\n",
    "            true_mean = to_dense(true_X[:,top_DEGs]).mean(axis = 0)\n",
    "\n",
    "            logger.debug(f\"Shape ctrl_adata with top DEGs: {ctrl_adata[:,top_DEGs].X.shape}, shape true_adata with top DEGs: {true_adata[:,top_DEGs].X.shape}\")\n",
    "\n",
    "\n",
    "            true_var = to_dense(true_X[:,top_DEGs]).var(axis = 0)\n",
    "            true_corr_mtx = np.corrcoef(to_dense(true_X[:,top_DEGs]), rowvar=False).flatten()\n",
    "            true_cov_mtx = np.cov(to_dense(true_X[:,top_DEGs]), rowvar=False).flatten()\n",
    "\n",
    "            pred_mean = to_dense(pred_X[:,top_DEGs]).mean(axis = 0)\n",
    "            logger.debug(f\"Shape of true_mean shape: {true_mean.shape}, ctrl_mean shape: {ctrl_mean.shape}, pred_mean shape: {pred_mean.shape}\")\n",
    "\n",
    "            pred_var = to_dense(pred_X[:,top_DEGs]).var(axis = 0)\n",
    "            pred_corr_mtx = np.corrcoef(to_dense(pred_X[:,top_DEGs]), rowvar=False).flatten()\n",
    "            pred_cov_mtx = np.cov(to_dense(pred_X[:,top_DEGs]), rowvar=False).flatten()\n",
    "\n",
    "            logger.debug(f\"Shape of true_var shape: {true_var.shape}, pred_var shape: {pred_var.shape}\")\n",
    "\n",
    "            true_sub_diff = true_mean - ctrl_mean\n",
    "            pred_sub_diff = pred_mean - ctrl_mean\n",
    "        \n",
    "            # inverse log1p to get sub change\n",
    "            true_diff = np.expm1(true_mean) - np.expm1(ctrl_mean)\n",
    "            pred_diff = np.expm1(pred_mean) - np.expm1(ctrl_mean)\n",
    "\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_R'] = pearsonr(true_sub_diff, pred_sub_diff)[0]\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_R2'] = pearsonr(true_sub_diff, pred_sub_diff)[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_sub_diff_MSE'] = (np.square(true_sub_diff - pred_sub_diff)).mean(axis=0)\n",
    "        \n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_R'] = pearsonr(true_diff, pred_diff)[0]\n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_R2'] = pearsonr(true_diff, pred_diff)[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_fold_diff_MSE'] = (np.square(true_diff - pred_diff)).mean(axis=0)\n",
    "    \n",
    "            results_dict[f'Top_{val}_DEGs_mean_R'] = pearsonr(true_mean, pred_mean)[0]\n",
    "            results_dict[f'Top_{val}_DEGs_mean_R2'] = pearsonr(true_mean, pred_mean)[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_mean_MSE'] = (np.square(true_mean - pred_mean)).mean(axis=0)\n",
    "\n",
    "            results_dict[f'Top_{val}_DEGs_var_R'] = pearsonr(true_var, pred_var)[0]\n",
    "            results_dict[f'Top_{val}_DEGs_var_R2'] = pearsonr(true_var, pred_var)[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_var_MSE'] = (np.square(true_var - pred_var)).mean(axis=0)\n",
    "\n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_R'] = pearsonr(true_corr_mtx.flatten(), pred_corr_mtx.flatten())[0]\n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_R2'] = pearsonr(true_corr_mtx.flatten(), pred_corr_mtx.flatten())[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_corr_mtx_MSE'] = (np.square(true_corr_mtx.flatten() - pred_corr_mtx.flatten())).mean(axis=0)\n",
    "\n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_R'] = pearsonr(true_cov_mtx.flatten(), pred_cov_mtx.flatten())[0]\n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_R2'] = pearsonr(true_cov_mtx.flatten(), pred_cov_mtx.flatten())[0]**2\n",
    "            results_dict[f'Top_{val}_DEGs_cov_mtx_MSE'] = (np.square(true_cov_mtx.flatten() - pred_cov_mtx.flatten())).mean(axis=0)\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "def get_DEG_Coverage_Recall(true_DEGs, pred_DEGs, p_cutoff):\n",
    "    sig_true_DEGs = true_DEGs[true_DEGs['pvals_adj'] < p_cutoff]\n",
    "    true_DEGs_with_direction = [get_DEG_with_direction(gene,score) for gene, score in zip(sig_true_DEGs.index, sig_true_DEGs['scores'])]\n",
    "    sig_pred_DEGs = pred_DEGs[pred_DEGs['pvals_adj'] < p_cutoff]\n",
    "    pred_DEGs_with_direction = [get_DEG_with_direction(gene,score) for gene, score in zip(sig_pred_DEGs.index, sig_pred_DEGs['scores'])]\n",
    "    num_true_DEGs = len(true_DEGs_with_direction)\n",
    "    num_pred_DEGs = len(pred_DEGs_with_direction)\n",
    "    num_overlapping_DEGs = len(set(true_DEGs_with_direction).intersection(set(pred_DEGs_with_direction)))\n",
    "    if num_true_DEGs > 0: \n",
    "        COVERAGE = num_overlapping_DEGs/num_true_DEGs\n",
    "    else:\n",
    "        COVERAGE = None\n",
    "    if num_pred_DEGs > 0:\n",
    "        RECALL = num_overlapping_DEGs/num_pred_DEGs\n",
    "    else:\n",
    "        RECALL = None\n",
    "    return COVERAGE, RECALL\n",
    "\n",
    "def get_DEGs_overlaps(true_DEGs, pred_DEGs, DEG_vals, pval_threshold, lfc_threshold):\n",
    "    if lfc_threshold:\n",
    "        significant_true_DEGs = true_DEGs[(true_DEGs['pvals_adj'] < pval_threshold) & (abs(true_DEGs['lfc']) > lfc_threshold)]\n",
    "        significant_pred_DEGs = pred_DEGs[(pred_DEGs['pvals_adj'] < pval_threshold) & (abs(pred_DEGs['lfc']) > lfc_threshold)]\n",
    "    else:\n",
    "        significant_true_DEGs = true_DEGs[true_DEGs['pvals_adj'] < pval_threshold]\n",
    "        significant_pred_DEGs = pred_DEGs[pred_DEGs['pvals_adj'] < pval_threshold]\n",
    "\n",
    "    true_DEGs_for_comparison = [get_DEG_with_direction(gene,score) for gene, score in zip(significant_true_DEGs.index, significant_true_DEGs['scores'])]   \n",
    "    pred_DEGs_for_comparison = [get_DEG_with_direction(gene,score) for gene, score in zip(significant_pred_DEGs.index, significant_pred_DEGs['scores'])]\n",
    "    \n",
    "    logger.debug(f\"Computing DEG overlaps, # of significant DEGs in true data: {len(true_DEGs_for_comparison)}, # of significant DEGs in pred data: {len(pred_DEGs_for_comparison)}\")\n",
    "    num_DEGs = len(significant_true_DEGs)\n",
    "    DEG_vals.insert(0, num_DEGs)\n",
    "    \n",
    "    results = {}\n",
    "    for val in DEG_vals:\n",
    "        if val > num_DEGs:\n",
    "            results[f'Overlap_in_top_{val}_DEGs'] = None\n",
    "        else:\n",
    "            results[f'Overlap_in_top_{val}_DEGs'] = len(set(true_DEGs_for_comparison[0:val]).intersection(set(pred_DEGs_for_comparison[0:val])))\n",
    "\n",
    "    intersection = len(set(true_DEGs_for_comparison).intersection(set(pred_DEGs_for_comparison)))\n",
    "    union = len(set(true_DEGs_for_comparison).union(set(pred_DEGs_for_comparison)))\n",
    "    if union > 0:\n",
    "        results['Jaccard'] = intersection/union\n",
    "    else:\n",
    "        results['Jaccard'] = None\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_and_mse = get_eval(control, true_pert, pred_pert, true_DEGs_df, [100,50,20], pval_threshold, log_fold_change_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 10:31:28,863 - INFO - Running evaluation\n",
      "2025-01-31 10:31:28,864 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/repogle_k562_essential_raw.yaml\n",
      "2025-01-31 10:31:28,866 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNB_raw.yaml\n",
      "2025-01-31 10:31:28,868 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/adamson_INCOMPLETE.yaml\n",
      "2025-01-31 10:31:28,869 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNB_HVG.yaml\n",
      "2025-01-31 10:31:28,871 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/kang.yaml\n",
      "2025-01-31 10:31:28,874 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/essential_gene_knockouts_raw.yaml\n",
      "2025-01-31 10:31:28,876 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNG_raw_INCOMPLETE.yaml\n",
      "2025-01-31 10:31:28,877 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNG_raw.yaml\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "logger.info(\"Running evaluation\")\n",
    "\n",
    "# evaluate each pair of cells and perts\n",
    "eval_dict = {}\n",
    "for cell_id, pert_id, ctrl_data, gt_data in loader.get_eval_data():\n",
    "    logger.debug(f\"Making predictions for cell: {cell_id}, pert: {pert_id}\")\n",
    "\n",
    "    preds = model.make_predict(ctrl_data, pert_id, cell_id)\n",
    "    eval_dict[(cell_id, pert_id)] = (ctrl_data.X.toarray(), gt_data.X.toarray(), preds)\n",
    "    break\n",
    "    \n",
    "if not config.etl_config.log1p:\n",
    "    for (cell, pert) in eval_dict:  \n",
    "        ctrl_data, gt_data, pred_pert = eval_dict[(cell, pert)]\n",
    "        eval_dict[(cell, pert)] =  (np.log1p(ctrl_data), np.log1p(gt_data), np.log1p(pred_pert))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 10:41:37,979 - INFO - Getting ground Truth DEGs for RPL15 and k562\n",
      "/home/njwfish/miniconda3/envs/omnicell/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "2025-01-31 10:41:45,897 - INFO - Number of significant DEGS from ground truth: 2159\n",
      "2025-01-31 10:41:45,897 - INFO - Getting predicted DEGs for RPL15 and k562\n",
      "/home/njwfish/miniconda3/envs/omnicell/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "2025-01-31 10:42:04,082 - INFO - Getting evaluation metrics for RPL15 and k562\n",
      "2025-01-31 10:42:32,070 - INFO - Getting DEG overlaps for RPL15 and k562\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "from omnicell.evaluation.utils import get_DEGs, get_eval, get_DEG_Coverage_Recall, get_DEGs_overlaps\n",
    "pval_threshold = 0.05\n",
    "log_fold_change_threshold = 0.0\n",
    "\n",
    "results_dict = {}\n",
    "for (cell, pert) in eval_dict:  \n",
    "    ctrl_data, gt_data, pred_pert = eval_dict[(cell, pert)]\n",
    "\n",
    "    pred_pert = sc.AnnData(X=pred_pert)\n",
    "    true_pert = sc.AnnData(X=gt_data)\n",
    "    control = sc.AnnData(X=ctrl_data)\n",
    "\n",
    "    logger.info(f\"Getting ground Truth DEGs for {pert} and {cell}\")\n",
    "    true_DEGs_df = get_DEGs(control, true_pert)\n",
    "    signif_true_DEG = true_DEGs_df[true_DEGs_df['pvals_adj'] < pval_threshold]\n",
    "\n",
    "    logger.info(f\"Number of significant DEGS from ground truth: {signif_true_DEG.shape[0]}\")\n",
    "\n",
    "    logger.info(f\"Getting predicted DEGs for {pert} and {cell}\")\n",
    "    pred_DEGs_df = get_DEGs(control, pred_pert)\n",
    "\n",
    "\n",
    "    logger.info(f\"Getting evaluation metrics for {pert} and {cell}\")\n",
    "    r2_and_mse = get_eval(control, true_pert, pred_pert, true_DEGs_df, [100,50,20], pval_threshold, log_fold_change_threshold)\n",
    "\n",
    "    logger.info(f\"Getting DEG overlaps for {pert} and {cell}\")\n",
    "    DEGs_overlaps = get_DEGs_overlaps(true_DEGs_df, pred_DEGs_df, [100,50,20], pval_threshold, log_fold_change_threshold)\n",
    "\n",
    "    results_dict[(cell, pert)] = (r2_and_mse, DEGs_overlaps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell: k562, Pert: RPL15\n",
      "DEGs Overlaps: {'Overlap_in_top_2159_DEGs': 875, 'Overlap_in_top_100_DEGs': 4, 'Overlap_in_top_50_DEGs': 0, 'Overlap_in_top_20_DEGs': 0, 'Jaccard': 0.17341105257258155}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for (cell, pert) in results_dict:\n",
    "    r2_and_mse, DEGs_overlaps = results_dict[(cell, pert)]\n",
    "    print(f\"Cell: {cell}, Pert: {pert}\")\n",
    "    # print(f\"R2 and MSE: {r2_and_mse}\")\n",
    "    print(f\"DEGs Overlaps: {DEGs_overlaps}\")\n",
    "    print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_genes_mean_sub_diff_R': np.float64(0.6966497841526466),\n",
       " 'all_genes_mean_sub_diff_R2': np.float64(0.485320921759929),\n",
       " 'all_genes_mean_sub_diff_MSE': np.float64(0.01054379975115533),\n",
       " 'all_genes_mean_fold_diff_R': np.float64(0.7028902237471792),\n",
       " 'all_genes_mean_fold_diff_R2': np.float64(0.4940546666393597),\n",
       " 'all_genes_mean_fold_diff_MSE': np.float64(7.89763734207286),\n",
       " 'all_genes_mean_R': np.float64(0.9880260038744728),\n",
       " 'all_genes_mean_R2': np.float64(0.9761953843321598),\n",
       " 'all_genes_mean_MSE': np.float64(0.010543799755630833),\n",
       " 'all_genes_var_R': np.float64(0.8846038081846144),\n",
       " 'all_genes_var_R2': np.float64(0.7825238974547221),\n",
       " 'all_genes_var_MSE': np.float64(0.003680699246692525),\n",
       " 'all_genes_corr_mtx_R': np.float64(0.5764657556881528),\n",
       " 'all_genes_corr_mtx_R2': np.float64(0.3323127674811131),\n",
       " 'all_genes_corr_mtx_MSE': np.float64(0.0074322404434879),\n",
       " 'all_genes_cov_mtx_R': np.float64(0.7999105612729749),\n",
       " 'all_genes_cov_mtx_R2': np.float64(0.6398569060360457),\n",
       " 'all_genes_cov_mtx_MSE': np.float64(0.00043289714800753164),\n",
       " 'Top_2159_DEGs_sub_diff_R': np.float64(0.7150896212223927),\n",
       " 'Top_2159_DEGs_sub_diff_R2': np.float64(0.5113531663799851),\n",
       " 'Top_2159_DEGs_sub_diff_MSE': np.float64(0.03746614363330951),\n",
       " 'Top_2159_DEGs_fold_diff_R': np.float64(0.7042153178411117),\n",
       " 'Top_2159_DEGs_fold_diff_R2': np.float64(0.49591921388205795),\n",
       " 'Top_2159_DEGs_fold_diff_MSE': np.float64(31.280128761344674),\n",
       " 'Top_2159_DEGs_mean_R': np.float64(0.9854054550159079),\n",
       " 'Top_2159_DEGs_mean_R2': np.float64(0.9710239107751085),\n",
       " 'Top_2159_DEGs_mean_MSE': np.float64(0.037466143651030015),\n",
       " 'Top_2159_DEGs_var_R': np.float64(0.7313424466730446),\n",
       " 'Top_2159_DEGs_var_R2': np.float64(0.5348617743057151),\n",
       " 'Top_2159_DEGs_var_MSE': np.float64(0.012811103741294688),\n",
       " 'Top_2159_DEGs_corr_mtx_R': np.float64(0.7787662696275037),\n",
       " 'Top_2159_DEGs_corr_mtx_R2': np.float64(0.6064769027095378),\n",
       " 'Top_2159_DEGs_corr_mtx_MSE': np.float64(0.010277459901281946),\n",
       " 'Top_2159_DEGs_cov_mtx_R': np.float64(0.8461154485281228),\n",
       " 'Top_2159_DEGs_cov_mtx_R2': np.float64(0.7159113522379464),\n",
       " 'Top_2159_DEGs_cov_mtx_MSE': np.float64(0.002035454760013577),\n",
       " 'Top_100_DEGs_sub_diff_R': np.float64(0.6605864243512193),\n",
       " 'Top_100_DEGs_sub_diff_R2': np.float64(0.43637442403712917),\n",
       " 'Top_100_DEGs_sub_diff_MSE': np.float64(0.26779259171178843),\n",
       " 'Top_100_DEGs_fold_diff_R': np.float64(0.6263366978780645),\n",
       " 'Top_100_DEGs_fold_diff_R2': np.float64(0.39229765910879777),\n",
       " 'Top_100_DEGs_fold_diff_MSE': np.float64(564.313126353079),\n",
       " 'Top_100_DEGs_mean_R': np.float64(0.9730704738712052),\n",
       " 'Top_100_DEGs_mean_R2': np.float64(0.9468661471199318),\n",
       " 'Top_100_DEGs_mean_MSE': np.float64(0.26779259215430656),\n",
       " 'Top_100_DEGs_var_R': np.float64(0.25903013493172955),\n",
       " 'Top_100_DEGs_var_R2': np.float64(0.06709661080275002),\n",
       " 'Top_100_DEGs_var_MSE': np.float64(0.14265730505071558),\n",
       " 'Top_100_DEGs_corr_mtx_R': np.float64(0.8841630411394016),\n",
       " 'Top_100_DEGs_corr_mtx_R2': np.float64(0.7817442833168752),\n",
       " 'Top_100_DEGs_corr_mtx_MSE': np.float64(0.05694077635603237),\n",
       " 'Top_100_DEGs_cov_mtx_R': np.float64(0.8658246150682101),\n",
       " 'Top_100_DEGs_cov_mtx_R2': np.float64(0.7496522640580141),\n",
       " 'Top_100_DEGs_cov_mtx_MSE': np.float64(0.06262752591291998),\n",
       " 'Top_50_DEGs_sub_diff_R': np.float64(0.6652204121762533),\n",
       " 'Top_50_DEGs_sub_diff_R2': np.float64(0.4425181967759443),\n",
       " 'Top_50_DEGs_sub_diff_MSE': np.float64(0.35055931242706106),\n",
       " 'Top_50_DEGs_fold_diff_R': np.float64(0.5265366651350396),\n",
       " 'Top_50_DEGs_fold_diff_R2': np.float64(0.27724085973152884),\n",
       " 'Top_50_DEGs_fold_diff_MSE': np.float64(773.4531602426496),\n",
       " 'Top_50_DEGs_mean_R': np.float64(0.9697628446584043),\n",
       " 'Top_50_DEGs_mean_R2': np.float64(0.9404399748799604),\n",
       " 'Top_50_DEGs_mean_MSE': np.float64(0.35055931320925326),\n",
       " 'Top_50_DEGs_var_R': np.float64(0.2891948646056018),\n",
       " 'Top_50_DEGs_var_R2': np.float64(0.08363366971425235),\n",
       " 'Top_50_DEGs_var_MSE': np.float64(0.19822165764594668),\n",
       " 'Top_50_DEGs_corr_mtx_R': np.float64(0.879576184934372),\n",
       " 'Top_50_DEGs_corr_mtx_R2': np.float64(0.7736542651037045),\n",
       " 'Top_50_DEGs_corr_mtx_MSE': np.float64(0.0728897800648223),\n",
       " 'Top_50_DEGs_cov_mtx_R': np.float64(0.8692461301387974),\n",
       " 'Top_50_DEGs_cov_mtx_R2': np.float64(0.755588834761275),\n",
       " 'Top_50_DEGs_cov_mtx_MSE': np.float64(0.08147196269878776),\n",
       " 'Top_20_DEGs_sub_diff_R': np.float64(0.6670738827842734),\n",
       " 'Top_20_DEGs_sub_diff_R2': np.float64(0.4449875650928865),\n",
       " 'Top_20_DEGs_sub_diff_MSE': np.float64(0.47194001982104367),\n",
       " 'Top_20_DEGs_fold_diff_R': np.float64(0.8376632915274399),\n",
       " 'Top_20_DEGs_fold_diff_R2': np.float64(0.7016797899725847),\n",
       " 'Top_20_DEGs_fold_diff_MSE': np.float64(862.991452003021),\n",
       " 'Top_20_DEGs_mean_R': np.float64(0.9649438563837157),\n",
       " 'Top_20_DEGs_mean_R2': np.float64(0.931116645972677),\n",
       " 'Top_20_DEGs_mean_MSE': np.float64(0.4719400219127069),\n",
       " 'Top_20_DEGs_var_R': np.float64(0.3307053524628576),\n",
       " 'Top_20_DEGs_var_R2': np.float64(0.10936603014758287),\n",
       " 'Top_20_DEGs_var_MSE': np.float64(0.3084311682765299),\n",
       " 'Top_20_DEGs_corr_mtx_R': np.float64(0.814644571536373),\n",
       " 'Top_20_DEGs_corr_mtx_R2': np.float64(0.6636457779336808),\n",
       " 'Top_20_DEGs_corr_mtx_MSE': np.float64(0.09212498889395444),\n",
       " 'Top_20_DEGs_cov_mtx_R': np.float64(0.7989236789224949),\n",
       " 'Top_20_DEGs_cov_mtx_R2': np.float64(0.6382790447430537),\n",
       " 'Top_20_DEGs_cov_mtx_MSE': np.float64(0.09457834626385779)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_and_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000000,) (4000000,)\n",
      "Naive R²: 0.008483\n",
      "Efficient R²: 0.994205\n"
     ]
    }
   ],
   "source": [
    "def efficient_correlation_r2_pearson(U, V):\n",
    "    \"\"\"\n",
    "    Compute squared Pearson correlation between correlation matrices \n",
    "    without forming full matrices\n",
    "    \"\"\"\n",
    "    n = U.shape[0]\n",
    "    \n",
    "    # Normalize U and V\n",
    "    U_norms = np.sqrt(np.sum(U * U, axis=1, keepdims=True))\n",
    "    U_normalized = U / U_norms\n",
    "    \n",
    "    V_norms = np.sqrt(np.sum(V * V, axis=1, keepdims=True))\n",
    "    V_normalized = V / V_norms\n",
    "    \n",
    "    # Compute correlation matrices implicitly\n",
    "    UTU = U_normalized.T @ U_normalized\n",
    "    VTV = V_normalized.T @ V_normalized\n",
    "    \n",
    "    # Compute means without forming full matrices\n",
    "    mean_UTU = np.sum(UTU) / (n * n)\n",
    "    mean_VTV = np.sum(VTV) / (n * n)\n",
    "    \n",
    "    # Center the matrices implicitly\n",
    "    UTU_centered = UTU - mean_UTU\n",
    "    VTV_centered = VTV - mean_VTV\n",
    "    \n",
    "    # Compute correlation using trace tricks\n",
    "    numerator = np.sum(UTU_centered * VTV_centered)\n",
    "    denominator = np.sqrt(np.sum(UTU_centered * UTU_centered) * \n",
    "                         np.sum(VTV_centered * VTV_centered))\n",
    "    \n",
    "    r = numerator / denominator\n",
    "    return r * r\n",
    "\n",
    "def naive_correlation_r2(X1, X2):\n",
    "    \"\"\"\n",
    "    Original implementation using flattened matrices\n",
    "    \"\"\"\n",
    "    true_corr_mtx = np.corrcoef(X1).flatten()\n",
    "    pred_corr_mtx = np.corrcoef(X2).flatten()\n",
    "    print(true_corr_mtx.shape, pred_corr_mtx.shape)\n",
    "    \n",
    "    return pearsonr(true_corr_mtx, pred_corr_mtx)[0] ** 2\n",
    "\n",
    "# Test both implementations\n",
    "np.random.seed(42)\n",
    "n, k = 2000, 10\n",
    "U = np.random.randn(n, k)\n",
    "V = np.random.randn(n, k)\n",
    "V[:, :1] = U[:, :1]  # Make them partially similar\n",
    "\n",
    "naive_result = naive_correlation_r2(U, V)\n",
    "efficient_result = efficient_correlation_r2_pearson(U, V)\n",
    "\n",
    "print(f\"Naive R²: {naive_result:.6f}\")\n",
    "print(f\"Efficient R²: {efficient_result:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive R²: 0.008483\n",
      "Efficient R²: 0.993551\n",
      "\n",
      "First few elements of correlation matrices:\n",
      "True corr (naive): [ 1.         -0.11051098 -0.31666654 -0.15239374  0.07219922]\n",
      "True corr (efficient): [ 1.          0.02817255  0.0274025   0.01609295 -0.0151037 ]\n"
     ]
    }
   ],
   "source": [
    "def efficient_correlation_r2_pearson(U, V):\n",
    "    \"\"\"\n",
    "    Compute squared Pearson correlation between correlation matrices \n",
    "    without forming full matrices, matching np.corrcoef exactly\n",
    "    \"\"\"\n",
    "    # First compute the correlation matrices exactly as numpy does\n",
    "    true_corr = np.corrcoef(U.T)  # Note: using .T to match np.corrcoef default behavior\n",
    "    pred_corr = np.corrcoef(V.T)\n",
    "    \n",
    "    # Now compute Pearson R² between these matrices without flattening\n",
    "    mean_true = np.mean(true_corr)\n",
    "    mean_pred = np.mean(pred_corr)\n",
    "    \n",
    "    # Center the matrices\n",
    "    true_centered = true_corr - mean_true\n",
    "    pred_centered = pred_corr - mean_pred\n",
    "    \n",
    "    # Compute correlation\n",
    "    numerator = np.sum(true_centered * pred_centered)\n",
    "    denominator = np.sqrt(np.sum(true_centered * true_centered) * \n",
    "                         np.sum(pred_centered * pred_centered))\n",
    "    \n",
    "    r = numerator / denominator\n",
    "    return r * r\n",
    "\n",
    "def naive_correlation_r2(X1, X2):\n",
    "    \"\"\"\n",
    "    Original implementation using flattened matrices\n",
    "    \"\"\"\n",
    "    true_corr_mtx = np.corrcoef(X1).flatten()\n",
    "    pred_corr_mtx = np.corrcoef(X2).flatten()\n",
    "    \n",
    "    return pearsonr(true_corr_mtx, pred_corr_mtx)[0] ** 2\n",
    "\n",
    "# Test both implementations\n",
    "np.random.seed(42)\n",
    "n, k = 2000, 10\n",
    "U = np.random.randn(n, k)\n",
    "V = np.random.randn(n, k)\n",
    "V[:, :1] = U[:, :1]  # Make them partially similar\n",
    "\n",
    "naive_result = naive_correlation_r2(U, V)\n",
    "efficient_result = efficient_correlation_r2_pearson(U, V)\n",
    "\n",
    "print(f\"Naive R²: {naive_result:.6f}\")\n",
    "print(f\"Efficient R²: {efficient_result:.6f}\")\n",
    "\n",
    "# Let's also print the actual correlation matrices to verify\n",
    "print(\"\\nFirst few elements of correlation matrices:\")\n",
    "print(\"True corr (naive):\", np.corrcoef(U).flatten()[:5])\n",
    "print(\"True corr (efficient):\", np.corrcoef(U.T).flatten()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) (100,)\n",
      "Naive R²: 0.993551\n",
      "Efficient R²: 0.993551\n",
      "\n",
      "First few elements of correlation matrices:\n",
      "True corr (naive): [ 1.          0.02817255  0.0274025   0.01609295 -0.0151037 ]\n",
      "True corr (efficient): [ 1.          0.02817255  0.0274025   0.01609295 -0.0151037 ]\n"
     ]
    }
   ],
   "source": [
    "def efficient_correlation_r2_pearson(U, V):\n",
    "    \"\"\"\n",
    "    Compute squared Pearson correlation between correlation matrices \n",
    "    without forming full matrices, matching np.corrcoef exactly\n",
    "    \"\"\"\n",
    "    # First compute the correlation matrices exactly as numpy does\n",
    "    true_corr = np.corrcoef(U, rowvar=False)  # correlations between columns\n",
    "    pred_corr = np.corrcoef(V, rowvar=False)\n",
    "    \n",
    "    # Now compute Pearson R² between these matrices without flattening\n",
    "    mean_true = np.mean(true_corr)\n",
    "    mean_pred = np.mean(pred_corr)\n",
    "    \n",
    "    # Center the matrices\n",
    "    true_centered = true_corr - mean_true\n",
    "    pred_centered = pred_corr - mean_pred\n",
    "    \n",
    "    # Compute correlation\n",
    "    numerator = np.sum(true_centered * pred_centered)\n",
    "    denominator = np.sqrt(np.sum(true_centered * true_centered) * \n",
    "                         np.sum(pred_centered * pred_centered))\n",
    "    \n",
    "    r = numerator / denominator\n",
    "    return r * r\n",
    "\n",
    "def naive_correlation_r2(X1, X2):\n",
    "    \"\"\"\n",
    "    Original implementation using flattened matrices\n",
    "    \"\"\"\n",
    "    true_corr_mtx = np.corrcoef(X1, rowvar=False).flatten()  # correlations between columns\n",
    "    pred_corr_mtx = np.corrcoef(X2, rowvar=False).flatten()\n",
    "    print(true_corr_mtx.shape, pred_corr_mtx.shape)\n",
    "    \n",
    "    return pearsonr(true_corr_mtx, pred_corr_mtx)[0] ** 2\n",
    "\n",
    "# Test both implementations\n",
    "np.random.seed(42)\n",
    "n, k = 2000, 10\n",
    "U = np.random.randn(n, k)\n",
    "V = np.random.randn(n, k)\n",
    "V[:, :1] = U[:, :1]  # Make them partially similar\n",
    "\n",
    "naive_result = naive_correlation_r2(U, V)\n",
    "efficient_result = efficient_correlation_r2_pearson(U, V)\n",
    "\n",
    "print(f\"Naive R²: {naive_result:.6f}\")\n",
    "print(f\"Efficient R²: {efficient_result:.6f}\")\n",
    "\n",
    "# Let's also print the first few elements to verify they're the same\n",
    "print(\"\\nFirst few elements of correlation matrices:\")\n",
    "print(\"True corr (naive):\", np.corrcoef(U, rowvar=False).flatten()[:5])\n",
    "print(\"True corr (efficient):\", np.corrcoef(U, rowvar=False).flatten()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Size | Efficient Time (s) | Naive Time (s) | Speedup | Memory Usage (GB) | R² Match\n",
      "--------------------------------------------------------------------------------\n",
      "      1000 |          0.0195 |        0.0287 |    1.48x |          0.0101 | True\n",
      "      2000 |          0.0685 |        0.1144 |    1.67x |          0.0337 | True\n",
      "      5000 |          0.4692 |        0.7709 |    1.64x |          0.0232 | True\n",
      "     10000 |          1.9041 |        3.1527 |    1.66x |          0.0039 | True\n",
      "     20000 |          8.4055 |       12.9496 |    1.54x |          0.0060 | True\n",
      "\n",
      "Peak memory usage: 0.0500 GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Return memory usage in GB\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024 / 1024\n",
    "\n",
    "def efficient_correlation_r2_pearson(U, V):\n",
    "    \"\"\"Efficient version\"\"\"\n",
    "    U_centered = U - U.mean(axis=1, keepdims=True)\n",
    "    V_centered = V - V.mean(axis=1, keepdims=True)\n",
    "    \n",
    "    U_norms = np.sqrt(np.sum(U_centered * U_centered, axis=1, keepdims=True))\n",
    "    V_norms = np.sqrt(np.sum(V_centered * V_centered, axis=1, keepdims=True))\n",
    "    \n",
    "    U_normalized = U_centered / U_norms\n",
    "    V_normalized = V_centered / V_norms\n",
    "    \n",
    "    UTU = U_normalized @ U_normalized.T\n",
    "    VTV = V_normalized @ V_normalized.T\n",
    "    \n",
    "    mean_UTU = np.mean(UTU)\n",
    "    mean_VTV = np.mean(VTV)\n",
    "    \n",
    "    UTU_centered = UTU - mean_UTU\n",
    "    VTV_centered = VTV - mean_VTV\n",
    "    \n",
    "    numerator = np.sum(UTU_centered * VTV_centered)\n",
    "    denominator = np.sqrt(np.sum(UTU_centered * UTU_centered) * \n",
    "                         np.sum(VTV_centered * VTV_centered))\n",
    "    \n",
    "    return (numerator / denominator) ** 2\n",
    "\n",
    "def naive_correlation_r2(X1, X2):\n",
    "    \"\"\"Naive version\"\"\"\n",
    "    true_corr_mtx = np.corrcoef(X1, rowvar=True).flatten()\n",
    "    pred_corr_mtx = np.corrcoef(X2, rowvar=True).flatten()\n",
    "    return pearsonr(true_corr_mtx, pred_corr_mtx)[0] ** 2\n",
    "\n",
    "# Test sizes (n_samples, keeping n_features=10 fixed)\n",
    "test_sizes = [1000, 2000, 5000, 10000, 20000]\n",
    "k = 10  # fixed number of features\n",
    "\n",
    "results = []\n",
    "initial_memory = get_memory_usage()\n",
    "\n",
    "print(\"Matrix Size | Efficient Time (s) | Naive Time (s) | Speedup | Memory Usage (GB) | R² Match\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for n in test_sizes:\n",
    "    # Generate random matrices\n",
    "    np.random.seed(42)\n",
    "    U = np.random.randn(n, k)\n",
    "    V = np.random.randn(n, k)\n",
    "    V[:, :1] = U[:, :1]  # Make them partially similar\n",
    "    \n",
    "    # Time efficient version\n",
    "    start_memory = get_memory_usage()\n",
    "    start_time = time.time()\n",
    "    eff_result = efficient_correlation_r2_pearson(U, V)\n",
    "    eff_time = time.time() - start_time\n",
    "    eff_memory = get_memory_usage() - start_memory\n",
    "    \n",
    "    # Time naive version\n",
    "    start_memory = get_memory_usage()\n",
    "    start_time = time.time()\n",
    "    naive_result = naive_correlation_r2(U, V)\n",
    "    naive_time = time.time() - start_time\n",
    "    naive_memory = get_memory_usage() - start_memory\n",
    "    \n",
    "    # Calculate metrics\n",
    "    speedup = naive_time / eff_time\n",
    "    max_memory = max(eff_memory, naive_memory)\n",
    "    results_match = np.abs(eff_result - naive_result) < 1e-10\n",
    "    \n",
    "    print(f\"{n:>10} | {eff_time:>15.4f} | {naive_time:>13.4f} | {speedup:>7.2f}x | {max_memory:>15.4f} | {results_match}\")\n",
    "    \n",
    "    # Clear some memory\n",
    "    del U, V\n",
    "\n",
    "print(f\"\\nPeak memory usage: {get_memory_usage() - initial_memory:.4f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Size | Efficient Low-Rank (s) | Original Efficient (s) | Naive (s) | Low-Rank Speedup\n",
      "------------------------------------------------------------------------------------------\n",
      "      1000 |             0.0004 |              0.0129 |    0.0281 |    65.57x\n",
      "      2000 |             0.0005 |              0.1083 |    0.2357 |   501.57x\n",
      "      5000 |             0.0013 |              0.8128 |    1.5112 |  1142.44x\n",
      "     10000 |             0.0084 |              2.3063 |    3.0373 |   361.15x\n",
      "     20000 |             0.0048 |              8.4146 |   12.9380 |  2719.95x\n"
     ]
    }
   ],
   "source": [
    "def efficient_correlation_r2_pearson_lowrank(U, V):\n",
    "    \"\"\"\n",
    "    Compute squared Pearson correlation between correlation matrices \n",
    "    exploiting low rank structure (n x k where k << n)\n",
    "    \"\"\"\n",
    "    # Center the data\n",
    "    U_centered = U - U.mean(axis=1, keepdims=True)\n",
    "    V_centered = V - V.mean(axis=1, keepdims=True)\n",
    "    \n",
    "    # Normalize rows\n",
    "    U_norms = np.sqrt(np.sum(U_centered * U_centered, axis=1, keepdims=True))\n",
    "    V_norms = np.sqrt(np.sum(V_centered * V_centered, axis=1, keepdims=True))\n",
    "    \n",
    "    U_normalized = U_centered / U_norms\n",
    "    V_normalized = V_centered / V_norms\n",
    "    \n",
    "    # Instead of forming n×n matrices, work with n×k matrices\n",
    "    # For the means, use the fact that tr(UU^T) = tr(U^TU)\n",
    "    UTU = U_normalized.T @ U_normalized  # k×k matrix\n",
    "    VTV = V_normalized.T @ V_normalized  # k×k matrix\n",
    "    \n",
    "    mean_UTU = np.sum(UTU) / (U.shape[0] ** 2)  # scalar\n",
    "    mean_VTV = np.sum(VTV) / (V.shape[0] ** 2)  # scalar\n",
    "    \n",
    "    # For the correlation computation:\n",
    "    # Instead of computing full UU^T * VV^T (n×n matrices)\n",
    "    # Use the fact that tr((UU^T)(VV^T)) = tr((U^TV)(V^TU))\n",
    "    UV = U_normalized.T @ V_normalized  # k×k matrix\n",
    "    \n",
    "    # Compute terms for numerator and denominator\n",
    "    trace_UUTVVT = np.sum(UV * UV.T)  # scalar\n",
    "    trace_UUTUUT = np.sum(UTU * UTU)  # scalar\n",
    "    trace_VVTVVT = np.sum(VTV * VTV)  # scalar\n",
    "    \n",
    "    n_squared = U.shape[0] ** 2\n",
    "    \n",
    "    # Compute correlation\n",
    "    numerator = trace_UUTVVT - n_squared * mean_UTU * mean_VTV\n",
    "    denominator = np.sqrt(\n",
    "        (trace_UUTUUT - n_squared * mean_UTU ** 2) * (trace_VVTVVT - n_squared * mean_VTV ** 2)\n",
    "    )\n",
    "    \n",
    "    r = numerator / denominator\n",
    "    return r * r\n",
    "\n",
    "# Test and compare all implementations\n",
    "np.random.seed(42)\n",
    "test_sizes = [1000, 2000, 5000, 10000, 20000]\n",
    "k = 10  # fixed number of features\n",
    "\n",
    "print(\"Matrix Size | Efficient Low-Rank (s) | Original Efficient (s) | Naive (s) | Low-Rank Speedup\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for n in test_sizes:\n",
    "    # Generate random matrices\n",
    "    U = np.random.randn(n, k)\n",
    "    V = np.random.randn(n, k)\n",
    "    V[:, :1] = U[:, :1]  # Make them partially similar\n",
    "    \n",
    "    # Time low-rank efficient version\n",
    "    start_time = time.time()\n",
    "    lowrank_result = efficient_correlation_r2_pearson_lowrank(U, V)\n",
    "    lowrank_time = time.time() - start_time\n",
    "    \n",
    "    # Time original efficient version\n",
    "    start_time = time.time()\n",
    "    eff_result = efficient_correlation_r2_pearson(U, V)\n",
    "    eff_time = time.time() - start_time\n",
    "    \n",
    "    # Time naive version\n",
    "    start_time = time.time()\n",
    "    naive_result = naive_correlation_r2(U, V)\n",
    "    naive_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate speedups\n",
    "    speedup_vs_efficient = eff_time / lowrank_time\n",
    "    speedup_vs_naive = naive_time / lowrank_time\n",
    "    \n",
    "    print(f\"{n:>10} | {lowrank_time:>18.4f} | {eff_time:>19.4f} | {naive_time:>9.4f} | {speedup_vs_naive:>8.2f}x\")\n",
    "    \n",
    "    # Verify results match\n",
    "    assert np.abs(lowrank_result - naive_result) < 1e-3, \"Results don't match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.006868941410695422), np.float64(0.006910486571052829))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowrank_result, naive_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Size | Rank1 | Rank2 | Time (s) | Result\n",
      "------------------------------------------------------------\n",
      "      1000 |     5 |    10 |   0.0004 | 0.372763\n",
      "Naive result: 0.372764\n",
      "      2000 |    10 |    20 |   0.0007 | 0.457513\n",
      "Naive result: 0.457513\n",
      "      5000 |    15 |    30 |   0.0549 | 0.469620\n"
     ]
    }
   ],
   "source": [
    "def efficient_correlation_r2_pearson_different_ranks(U, V):\n",
    "    \"\"\"\n",
    "    Compute squared Pearson correlation between correlation matrices \n",
    "    for matrices of different ranks\n",
    "    U: (n_samples x k1) matrix\n",
    "    V: (n_samples x k2) matrix\n",
    "    \"\"\"\n",
    "    # Center the data\n",
    "    U_centered = U - U.mean(axis=1, keepdims=True)\n",
    "    V_centered = V - V.mean(axis=1, keepdims=True)\n",
    "    \n",
    "    # Normalize rows\n",
    "    U_norms = np.sqrt(np.sum(U_centered * U_centered, axis=1, keepdims=True))\n",
    "    V_norms = np.sqrt(np.sum(V_centered * V_centered, axis=1, keepdims=True))\n",
    "    \n",
    "    U_normalized = U_centered / U_norms\n",
    "    V_normalized = V_centered / V_norms\n",
    "    \n",
    "    # Work with smaller matrices\n",
    "    UTU = U_normalized.T @ U_normalized  # k1×k1 matrix\n",
    "    VTV = V_normalized.T @ V_normalized  # k2×k2 matrix\n",
    "    UV = U_normalized.T @ V_normalized   # k1×k2 matrix\n",
    "    \n",
    "    # Compute means efficiently\n",
    "    mean_UTU = np.sum(UTU) / (U.shape[0] ** 2)\n",
    "    mean_VTV = np.sum(VTV) / (V.shape[0] ** 2)\n",
    "    \n",
    "    # Use trace tricks with different sized matrices\n",
    "    # For matrices of different sizes, tr(UU^T VV^T) = tr((U^TV)(V^TU)) = sum(UV * VU)\n",
    "    # print(UV.shape, V_normalized.T.shape, U_normalized.shape)\n",
    "    trace_UUTVVT = np.sum(UV.T * (V_normalized.T @ U_normalized))\n",
    "    trace_UUTUUT = np.sum(UTU * UTU)\n",
    "    trace_VVTVVT = np.sum(VTV * VTV)\n",
    "    \n",
    "    n_squared = U.shape[0] ** 2\n",
    "    \n",
    "    # Compute correlation\n",
    "    numerator = trace_UUTVVT - n_squared * mean_UTU * mean_VTV\n",
    "    denominator = np.sqrt((trace_UUTUUT - n_squared * mean_UTU ** 2) * \n",
    "                         (trace_VVTVVT - n_squared * mean_VTV ** 2))\n",
    "    \n",
    "    r = numerator / denominator\n",
    "    return r * r\n",
    "\n",
    "# Test with different ranks\n",
    "np.random.seed(42)\n",
    "test_sizes = [(1000, 5, 10), (2000, 10, 20), (5000, 15, 30)]  # (n_samples, k1, k2)\n",
    "\n",
    "print(\"Matrix Size | Rank1 | Rank2 | Time (s) | Result\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for n, k1, k2 in test_sizes:\n",
    "    # Generate random matrices of different ranks\n",
    "    U = np.random.randn(n, k1)\n",
    "    V = np.random.randn(n, k2)\n",
    "    \n",
    "    # Make them partially similar in their overlapping dimensions\n",
    "    min_k = min(k1, k2)\n",
    "    V[:, :min_k] = U[:, :min_k]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = efficient_correlation_r2_pearson_different_ranks(U, V)\n",
    "    computation_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"{n:>10} | {k1:>5} | {k2:>5} | {computation_time:>8.4f} | {result:.6f}\")\n",
    "    \n",
    "    naive_result = naive_correlation_r2(U, V)\n",
    "    print(f\"Naive result: {naive_result:.6f}\")\n",
    "    assert np.abs(result - naive_result) < 1e-3, f\"Results don't match! {result} vs {naive_result}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Size | Ranks  | Low-Rank Time (s) | Naive Time (s) | Speedup | Memory (GB) | R² Match\n",
      "------------------------------------------------------------------------------------------\n",
      "      1000 |  5,10 |          0.0004 |        0.1288 |  312.15x |     0.0444 | False\n",
      "  Low-rank result: 0.372763\n",
      "  Naive result:    0.372764\n",
      "  Difference:      2.22e-07\n",
      "      2000 | 10,20 |          0.0088 |        0.2531 |   28.76x |     0.0000 | False\n",
      "  Low-rank result: 0.450282\n",
      "  Naive result:    0.450281\n",
      "  Difference:      1.14e-06\n",
      "      5000 | 15,30 |          0.0362 |        1.1862 |   32.79x |     0.0232 | False\n",
      "  Low-rank result: 0.468363\n",
      "  Naive result:    0.468362\n",
      "  Difference:      5.20e-07\n",
      "     10000 | 20,40 |          0.0669 |        3.6951 |   55.21x |     0.0000 | False\n",
      "  Low-rank result: 0.471352\n",
      "  Naive result:    0.471352\n",
      "  Difference:      1.28e-07\n",
      "     20000 | 25,50 |          0.0160 |       13.2281 |  827.16x |     0.0065 | False\n",
      "  Low-rank result: 0.477505\n",
      "  Naive result:    0.477505\n",
      "  Difference:      1.19e-07\n",
      "\n",
      "Peak memory usage: 0.0316 GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Return memory usage in GB\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024 / 1024\n",
    "\n",
    "# Test sizes (n_samples, k1, k2)\n",
    "test_sizes = [\n",
    "    (1000, 5, 10),\n",
    "    (2000, 10, 20),\n",
    "    (5000, 15, 30),\n",
    "    (10000, 20, 40),\n",
    "    (20000, 25, 50)\n",
    "]\n",
    "\n",
    "results = []\n",
    "initial_memory = get_memory_usage()\n",
    "\n",
    "print(\"Matrix Size | Ranks  | Low-Rank Time (s) | Naive Time (s) | Speedup | Memory (GB) | R² Match\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for n, k1, k2 in test_sizes:\n",
    "    # Generate random matrices\n",
    "    np.random.seed(42)\n",
    "    U = np.random.randn(n, k1)\n",
    "    V = np.random.randn(n, k2)\n",
    "    V[:, :min(k1, k2)] = U[:, :min(k1, k2)]  # Make them partially similar\n",
    "    \n",
    "    # Time low-rank version\n",
    "    start_memory = get_memory_usage()\n",
    "    start_time = time.time()\n",
    "    lowrank_result = efficient_correlation_r2_pearson_different_ranks(U, V)\n",
    "    lowrank_time = time.time() - start_time\n",
    "    lowrank_memory = get_memory_usage() - start_memory\n",
    "    \n",
    "    # Time naive version\n",
    "    start_memory = get_memory_usage()\n",
    "    start_time = time.time()\n",
    "    naive_result = naive_correlation_r2(U, V)\n",
    "    naive_time = time.time() - start_time\n",
    "    naive_memory = get_memory_usage() - start_memory\n",
    "    \n",
    "    # Calculate metrics\n",
    "    speedup = naive_time / lowrank_time\n",
    "    max_memory = max(lowrank_memory, naive_memory)\n",
    "    results_match = np.abs(lowrank_result - naive_result) < 1e-10\n",
    "    \n",
    "    print(f\"{n:>10} | {k1:>2},{k2:>2} | {lowrank_time:>15.4f} | {naive_time:>13.4f} | {speedup:>7.2f}x | {max_memory:>10.4f} | {results_match}\")\n",
    "    \n",
    "    # Optional: print detailed results\n",
    "    if not results_match:\n",
    "        print(f\"  Low-rank result: {lowrank_result:.6f}\")\n",
    "        print(f\"  Naive result:    {naive_result:.6f}\")\n",
    "        print(f\"  Difference:      {abs(lowrank_result - naive_result):.2e}\")\n",
    "    \n",
    "    # Clear some memory\n",
    "    del U, V\n",
    "\n",
    "print(f\"\\nPeak memory usage: {get_memory_usage() - initial_memory:.4f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Size | Ranks  | Low-Rank Time (s) | Naive Time (s) | Speedup | Memory (GB) | R² Match\n",
      "------------------------------------------------------------------------------------------\n",
      "(1000000,) (1000000,)\n",
      "      1000 |  5,10 |          0.0003 |        0.0572 |  177.00x |     0.0019 | False\n",
      "  Low-rank result: 0.425432\n",
      "  Naive result:    0.425432\n",
      "  Difference:      2.76e-07\n",
      "(4000000,) (4000000,)\n",
      "      2000 | 10,20 |          0.0004 |        0.1078 |  253.86x |     0.0000 | False\n",
      "  Low-rank result: 0.473235\n",
      "  Naive result:    0.473234\n",
      "  Difference:      8.52e-07\n",
      "(25000000,) (25000000,)\n",
      "      5000 | 15,30 |          0.0141 |        0.8345 |   59.02x |     0.0232 | False\n",
      "  Low-rank result: 0.484887\n",
      "  Naive result:    0.484887\n",
      "  Difference:      4.63e-07\n",
      "(100000000,) (100000000,)\n",
      "     10000 | 20,40 |          0.4543 |        2.7394 |    6.03x |     0.0000 | False\n",
      "  Low-rank result: 0.484533\n",
      "  Naive result:    0.484533\n",
      "  Difference:      1.25e-07\n",
      "(400000000,) (400000000,)\n",
      "     20000 | 25,50 |          0.0103 |       11.1668 | 1083.31x |     0.0001 | False\n",
      "  Low-rank result: 0.487472\n",
      "  Naive result:    0.487472\n",
      "  Difference:      1.15e-07\n",
      "\n",
      "Peak memory usage: -0.0194 GB\n"
     ]
    }
   ],
   "source": [
    "def efficient_covariance_r2_pearson_different_ranks(U, V):\n",
    "    \"\"\"\n",
    "    Compute squared Pearson correlation between covariance matrices \n",
    "    for matrices of different ranks\n",
    "    U: (n_samples x k1) matrix\n",
    "    V: (n_samples x k2) matrix\n",
    "    \"\"\"\n",
    "    # Center the data\n",
    "    U_centered = U - U.mean(axis=1, keepdims=True)\n",
    "    V_centered = V - V.mean(axis=1, keepdims=True)\n",
    "    \n",
    "    # For covariance, we don't normalize by row norms\n",
    "    # Compute smaller matrices directly\n",
    "    UTU = U_centered.T @ U_centered  # k1×k1 matrix\n",
    "    VTV = V_centered.T @ V_centered  # k2×k2 matrix\n",
    "    UV = U_centered.T @ V_centered   # k1×k2 matrix\n",
    "    \n",
    "    # Compute means efficiently\n",
    "    mean_UTU = np.sum(UTU) / (U.shape[0] ** 2)\n",
    "    mean_VTV = np.sum(VTV) / (V.shape[0] ** 2)\n",
    "    \n",
    "    # Use trace tricks with different sized matrices\n",
    "    trace_UUTVVT = np.sum(UV.T * (V_centered.T @ U_centered))\n",
    "    trace_UUTUUT = np.sum(UTU * UTU)\n",
    "    trace_VVTVVT = np.sum(VTV * VTV)\n",
    "    \n",
    "    n_squared = U.shape[0] ** 2\n",
    "    \n",
    "    # Compute correlation\n",
    "    numerator = trace_UUTVVT - n_squared * mean_UTU * mean_VTV\n",
    "    denominator = np.sqrt((trace_UUTUUT - n_squared * mean_UTU ** 2) * \n",
    "                         (trace_VVTVVT - n_squared * mean_VTV ** 2))\n",
    "    \n",
    "    r = numerator / denominator\n",
    "    return r * r\n",
    "\n",
    "def naive_covariance_r2(X1, X2):\n",
    "    \"\"\"\n",
    "    Original implementation using flattened matrices\n",
    "    \"\"\"\n",
    "    true_cov_mtx = np.cov(X1, rowvar=True).flatten()\n",
    "    pred_cov_mtx = np.cov(X2, rowvar=True).flatten()\n",
    "    print(true_cov_mtx.shape, pred_cov_mtx.shape)\n",
    "    \n",
    "    return pearsonr(true_cov_mtx, pred_cov_mtx)[0] ** 2\n",
    "\n",
    "# Benchmark both implementations\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Return memory usage in GB\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024 / 1024\n",
    "\n",
    "# Test sizes (n_samples, k1, k2)\n",
    "test_sizes = [\n",
    "    (1000, 5, 10),\n",
    "    (2000, 10, 20),\n",
    "    (5000, 15, 30),\n",
    "    (10000, 20, 40),\n",
    "    (20000, 25, 50)\n",
    "]\n",
    "\n",
    "results = []\n",
    "initial_memory = get_memory_usage()\n",
    "\n",
    "print(\"Matrix Size | Ranks  | Low-Rank Time (s) | Naive Time (s) | Speedup | Memory (GB) | R² Match\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for n, k1, k2 in test_sizes:\n",
    "    # Generate random matrices\n",
    "    np.random.seed(42)\n",
    "    U = np.random.randn(n, k1)\n",
    "    V = np.random.randn(n, k2)\n",
    "    V[:, :min(k1, k2)] = U[:, :min(k1, k2)]  # Make them partially similar\n",
    "    \n",
    "    # Time low-rank version\n",
    "    start_memory = get_memory_usage()\n",
    "    start_time = time.time()\n",
    "    lowrank_result = efficient_covariance_r2_pearson_different_ranks(U, V)\n",
    "    lowrank_time = time.time() - start_time\n",
    "    lowrank_memory = get_memory_usage() - start_memory\n",
    "    \n",
    "    # Time naive version\n",
    "    start_memory = get_memory_usage()\n",
    "    start_time = time.time()\n",
    "    naive_result = naive_covariance_r2(U, V)\n",
    "    naive_time = time.time() - start_time\n",
    "    naive_memory = get_memory_usage() - start_memory\n",
    "    \n",
    "    # Calculate metrics\n",
    "    speedup = naive_time / lowrank_time\n",
    "    max_memory = max(lowrank_memory, naive_memory)\n",
    "    results_match = np.abs(lowrank_result - naive_result) < 1e-10\n",
    "    \n",
    "    print(f\"{n:>10} | {k1:>2},{k2:>2} | {lowrank_time:>15.4f} | {naive_time:>13.4f} | {speedup:>7.2f}x | {max_memory:>10.4f} | {results_match}\")\n",
    "    \n",
    "    # Optional: print detailed results\n",
    "    if not results_match:\n",
    "        print(f\"  Low-rank result: {lowrank_result:.6f}\")\n",
    "        print(f\"  Naive result:    {naive_result:.6f}\")\n",
    "        print(f\"  Difference:      {abs(lowrank_result - naive_result):.2e}\")\n",
    "    \n",
    "    # Clear some memory\n",
    "    del U, V\n",
    "\n",
    "print(f\"\\nPeak memory usage: {get_memory_usage() - initial_memory:.4f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnicell",
   "language": "python",
   "name": "omnicell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
